{
 "metadata": {
  "name": "",
  "signature": "sha256:76dc78087d8ff235bbcb05183d0400fc522bf1c66ec35735c1bd761d2dad0c81"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "import math\n",
      "from IPython.display import display, Image\n",
      "from scipy import ndimage\n",
      "import scipy.io as sio\n",
      "from sklearn.cross_validation import train_test_split\n",
      "import random\n",
      "from six.moves import cPickle as pickle\n",
      "from PIL import Image\n",
      "from scipy import ndimage\n",
      "import datetime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('train_processed.pickle', 'rb') as f:\n",
      "    train_data = pickle.load(f)\n",
      "    print(train_data.shape)\n",
      "    \n",
      "with open('train_processed_labels.pickle', 'rb') as f:\n",
      "    train_labels = pickle.load(f)\n",
      "    print(train_labels.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(33401, 32, 32, 1)\n",
        "(33401, 7)\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('test_processed.pickle', 'rb') as f:\n",
      "    test_data = pickle.load(f)\n",
      "    print(test_data.shape)\n",
      "    \n",
      "with open('test_processed_labels.pickle', 'rb') as f:\n",
      "    test_labels = pickle.load(f)\n",
      "    print(test_labels.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(13067, 32, 32, 1)\n",
        "(13067, 7)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('extra_processed.pickle', 'rb') as f:\n",
      "    extra_data = pickle.load(f)\n",
      "    print(extra_data.shape)\n",
      "    \n",
      "with open('extra_processed_labels.pickle', 'rb') as f:\n",
      "    extra_labels = pickle.load(f)\n",
      "    print(extra_labels.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(202352, 32, 32, 1)\n",
        "(202352, 7)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# JOINING THE IMAGES FROM THE TRAINING SET AND THE EXTRA SET INTO ONE LARGE TRAINING SET\n",
      "\n",
      "FLAGS_n = -1   # CHANGE TO THE NUMBER OF IMAGES TO BE USED FROM THE EXTRA SET\n",
      "\n",
      "def randomize(dataset, labels):\n",
      "    permutation = np.random.permutation(labels.shape[0])\n",
      "    shuffled_dataset = dataset[permutation,:,:]\n",
      "    shuffled_labels = labels[permutation,:]\n",
      "    return shuffled_dataset, shuffled_labels\n",
      "\n",
      "train_data = np.append(train_data, extra_data[:FLAGS_n,:,:], axis = 0)\n",
      "train_labels = np.append(train_labels, extra_labels[:FLAGS_n,:], axis = 0)\n",
      "\n",
      "del extra_data\n",
      "del extra_labels\n",
      "\n",
      "train_data, train_labels = randomize(train_data, train_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# SPLIT DATA INTO TRAINING AND VALIDATION SETS\n",
      "\n",
      "FLAGS_val_size = 5000.0 / np.float32(train_data.shape[0])\n",
      "train_data, val_data, train_labels, val_labels = train_test_split(\n",
      "    train_data, train_labels, test_size = FLAGS_val_size, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# USE 10.0 TO DENOTE ABSENCE OF A DIGIT.\n",
      "\n",
      "FLAGS_num_labels = 10\n",
      "\n",
      "def process_labels(labels):\n",
      "    np.place(labels,labels==10.0, 0.0)\n",
      "    np.place(labels,labels==-1.0, 10.0)\n",
      "    return\n",
      "\n",
      "process_labels(train_labels)\n",
      "process_labels(test_labels)\n",
      "process_labels(val_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# DISPLAY A FEW DITITS ANF THEIR LABELS TO MAKE SURE EVERYTHING IS STILL OK AFTER ALL THE PROCESSING\n",
      "\n",
      "n_test_display  = 0\n",
      "n_train_display = 0\n",
      "n_val_display   = 0\n",
      "\n",
      "for i in range(n_train_display):\n",
      "    j = random.randrange(np.shape(train_data)[0])\n",
      "    plt.imshow(train_data[j].reshape(32,32), cmap = 'Greys_r')\n",
      "    plt.title(train_labels[j])\n",
      "    plt.show()\n",
      "    \n",
      "\n",
      "for i in range(n_test_display):\n",
      "    j = random.randrange(np.shape(test_data)[0])\n",
      "    plt.imshow(test_data[j].reshape(32,32), cmap = 'Greys_r')\n",
      "    plt.title(test_labels[j])\n",
      "    plt.show()\n",
      "    \n",
      "\n",
      "for i in range(n_val_display):\n",
      "    j = random.randrange(np.shape(val_data)[0])\n",
      "    plt.imshow(val_data[j].reshape(32,32), cmap = 'Greys_r')\n",
      "    plt.title(val_labels[j])\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CHECK SHAPE AND SIZES \n",
      "\n",
      "print('Shape of the training image dataset:', train_data.shape)\n",
      "print('Shape of the training label set:', train_labels.shape)\n",
      "print('Shape of the validation image dataset:', val_data.shape)\n",
      "print('Shape of the validation label set:', val_labels.shape)\n",
      "print('Shape of the test image dataset:', test_data.shape)\n",
      "print('Shape of the test label set:', test_labels.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Shape of the training image dataset: (230752, 32, 32, 1)\n",
        "Shape of the training label set: (230752, 7)\n",
        "Shape of the validation image dataset: (5000, 32, 32, 1)\n",
        "Shape of the validation label set: (5000, 7)\n",
        "Shape of the test image dataset: (13067, 32, 32, 1)\n",
        "Shape of the test label set: (13067, 7)\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CONVERT TO ONE HOT LABELLING FORMAT\n",
      "\n",
      "def one_hot_label(labels):\n",
      "     return (np.arange(FLAGS_num_labels + 1) == labels[:,None]).astype(np.float32).reshape(-1, 5, 11)\n",
      "\n",
      "\n",
      "train_1hot_labels = one_hot_label(train_labels[:,:5].reshape(-1,))\n",
      "val_1hot_labels = one_hot_label(val_labels[:,:5].reshape(-1,))\n",
      "test_1hot_labels = one_hot_label(test_labels[:,:5].reshape(-1,))\n",
      "\n",
      "#del train_labels\n",
      "#del val_labels \n",
      "#del test_labels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CHECK SHAPES AND SIZES AGAIN\n",
      "\n",
      "print('Shape of the training image dataset:', train_data.shape)\n",
      "print('Shape of the training label set:', train_1hot_labels.shape)\n",
      "print('Shape of the validation image dataset:', val_data.shape)\n",
      "print('Shape of the validation label set:', val_1hot_labels.shape)\n",
      "print('Shape of the test image dataset:', test_data.shape)\n",
      "print('Shape of the test label set:', test_1hot_labels.shape)\n",
      "\n",
      "FLAGS_train_size = train_data.shape[0]\n",
      "FLAGS_val_size   = val_data.shape[0]\n",
      "FLAGS_test_size  = test_data.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Shape of the training image dataset: (230752, 32, 32, 1)\n",
        "Shape of the training label set: (230752, 5, 11)\n",
        "Shape of the validation image dataset: (5000, 32, 32, 1)\n",
        "Shape of the validation label set: (5000, 5, 11)\n",
        "Shape of the test image dataset: (13067, 32, 32, 1)\n",
        "Shape of the test label set: (13067, 5, 11)\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# DISPLAY A FEW IMAGES WITH ONE HOT LABELS\n",
      "\n",
      "n_test_display  = 0\n",
      "n_train_display = 0\n",
      "n_val_display   = 0\n",
      "\n",
      "\n",
      "for i in range(n_train_display):\n",
      "    j = random.randrange(np.shape(train_data)[0])\n",
      "    plt.imshow(train_data[j].reshape(32,32), cmap = 'Greys_r')\n",
      "    plt.title(train_1hot_labels[j])\n",
      "    plt.show()\n",
      "    \n",
      "\n",
      "for i in range(n_test_display):\n",
      "    j = random.randrange(np.shape(test_data)[0])\n",
      "    plt.imshow(test_data[j].reshape(32,32), cmap = 'Greys_r')\n",
      "    plt.title(test_1hot_labels[j])\n",
      "    plt.show()\n",
      "    \n",
      "\n",
      "for i in range(n_val_display):\n",
      "    j = random.randrange(np.shape(val_data)[0])\n",
      "    plt.imshow(val_data[j].reshape(32,32), cmap = 'Greys_r')\n",
      "    plt.title(val_1hot_labels[j])\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# COMPUTE ACCURACY\n",
      "\n",
      "FLAGS_digits_checked = 5 # NUMBER OF DIGITS TO CHECK. MAX FIVE.\n",
      "\n",
      "def accuracy(predictions, labels):\n",
      "    truth_table = np.zeros((predictions.shape[0],FLAGS_digits_checked))\n",
      "    for i in range(FLAGS_digits_checked):\n",
      "        truth_table[:,i] = np.argmax(predictions[:,i,:], 1) == np.argmax(labels[:,i,:], 1)\n",
      "    return (100 * np.sum(np.amin(truth_table, axis = 1))/predictions.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# BUILDING THE GRAPH\n",
      "\n",
      "FLAGS_image_size = 32\n",
      "FLAGS_batch_size = 64\n",
      "FLAGS_patch_size = 5\n",
      "\n",
      "FLAGS_depth1 = 64\n",
      "FLAGS_depth2 = 64\n",
      "FLAGS_depth3 = 64\n",
      "\n",
      "FLAGS_prob1 = 0.6\n",
      "FLAGS_prob2 = 0.95\n",
      "\n",
      "FLAGS_num_hidden1 = 64\n",
      "\n",
      "FLAGS_num_channels = 1\n",
      "\n",
      "\n",
      "graph = tf.Graph()\n",
      "\n",
      "with graph.as_default():  \n",
      "    \n",
      "    \n",
      "    # INPUT DATA\n",
      "    \n",
      "    tf_train_data = tf.placeholder(\n",
      "        tf.float32, shape=(FLAGS_batch_size, FLAGS_image_size, FLAGS_image_size, FLAGS_num_channels))\n",
      "    \n",
      "    tf_train_labels = tf.placeholder(tf.float32, shape=(FLAGS_batch_size, 5, FLAGS_num_labels + 1))\n",
      "        \n",
      "    \n",
      "    tf_val_data0 = tf.constant(val_data[0 * (FLAGS_val_size/10): 1 * (FLAGS_val_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_val_data1 = tf.constant(val_data[1 * (FLAGS_val_size/10): 2 * (FLAGS_val_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_val_data2 = tf.constant(val_data[2 * (FLAGS_val_size/10): 3 * (FLAGS_val_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_val_data3 = tf.constant(val_data[3 * (FLAGS_val_size/10): 4 * (FLAGS_val_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_val_data4 = tf.constant(val_data[4 * (FLAGS_val_size/10): 5 * (FLAGS_val_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_val_data5 = tf.constant(val_data[5 * (FLAGS_val_size/10): 6 * (FLAGS_val_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_val_data6 = tf.constant(val_data[6 * (FLAGS_val_size/10): 7 * (FLAGS_val_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_val_data7 = tf.constant(val_data[7 * (FLAGS_val_size/10): 8 * (FLAGS_val_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_val_data8 = tf.constant(val_data[8 * (FLAGS_val_size/10): 9 * (FLAGS_val_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_val_data9 = tf.constant(val_data[9 * (FLAGS_val_size/10):10 * (FLAGS_val_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "        \n",
      "    \n",
      "    tf_test_data0 = tf.constant(test_data[0 * (FLAGS_test_size/10): 1 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_test_data1 = tf.constant(test_data[1 * (FLAGS_test_size/10): 2 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_test_data2 = tf.constant(test_data[2 * (FLAGS_test_size/10): 3 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_test_data3 = tf.constant(test_data[3 * (FLAGS_test_size/10): 4 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_test_data4 = tf.constant(test_data[4 * (FLAGS_test_size/10): 5 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_test_data5 = tf.constant(test_data[5 * (FLAGS_test_size/10): 6 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_test_data6 = tf.constant(test_data[6 * (FLAGS_test_size/10): 7 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_test_data7 = tf.constant(test_data[7 * (FLAGS_test_size/10): 8 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_test_data8 = tf.constant(test_data[8 * (FLAGS_test_size/10): 9 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_test_data9 = tf.constant(test_data[9 * (FLAGS_test_size/10):10 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    \n",
      "    \n",
      "    # VARIABLES INITIALIZATION (TWO CONVOLUTION LAYERS WITH SHARED WEIGHTS)\n",
      "    \n",
      "    conv_layer1_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_patch_size, FLAGS_patch_size, FLAGS_num_channels, FLAGS_depth1], stddev=0.1))\n",
      "    conv_layer1_biases = tf.Variable(tf.zeros([FLAGS_depth1]))\n",
      "    \n",
      "    conv_layer2_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_patch_size, FLAGS_patch_size, FLAGS_depth1, FLAGS_depth2], stddev=0.1))\n",
      "    conv_layer2_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_depth2]))\n",
      "    \n",
      "    conv_layer3_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_patch_size, FLAGS_patch_size, FLAGS_depth2, FLAGS_depth3], stddev=0.1))\n",
      "    conv_layer3_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_depth3]))\n",
      "   \n",
      "    \n",
      "    # VARIABLES INITIALIZATION (FIRST FULLY CONNECTED LAYER WITH NON_SHARED WEIGHTS)\n",
      "    \n",
      "    full_digit0_layer1_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_image_size // 4 * FLAGS_image_size // 4 * FLAGS_depth3, FLAGS_num_hidden1], stddev=0.1))\n",
      "    full_digit0_layer1_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_num_hidden1]))\n",
      "    \n",
      "    full_digit1_layer1_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_image_size // 4 * FLAGS_image_size // 4 * FLAGS_depth3, FLAGS_num_hidden1], stddev=0.1))\n",
      "    full_digit1_layer1_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_num_hidden1]))\n",
      "    \n",
      "    full_digit2_layer1_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_image_size // 4 * FLAGS_image_size // 4 * FLAGS_depth3, FLAGS_num_hidden1], stddev=0.1))\n",
      "    full_digit2_layer1_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_num_hidden1]))\n",
      "    \n",
      "    full_digit3_layer1_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_image_size // 4 * FLAGS_image_size // 4 * FLAGS_depth3, FLAGS_num_hidden1], stddev=0.1))\n",
      "    full_digit3_layer1_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_num_hidden1]))\n",
      "    \n",
      "    full_digit4_layer1_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_image_size // 4 * FLAGS_image_size // 4 * FLAGS_depth3, FLAGS_num_hidden1], stddev=0.1))\n",
      "    full_digit4_layer1_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_num_hidden1]))\n",
      "    \n",
      "    \n",
      "    \n",
      "    # VARIABLES INITIALIZATION (SECOND FULLY CONNECTED LAYER WITH NON_SHARED WEIGHTS)\n",
      "    \n",
      "    full_digit0_layer2_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_num_hidden1, FLAGS_num_labels + 1], stddev=0.1))\n",
      "    full_digit0_layer2_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_num_labels + 1]))\n",
      "    \n",
      "    full_digit1_layer2_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_num_hidden1, FLAGS_num_labels + 1], stddev=0.1))\n",
      "    full_digit1_layer2_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_num_labels + 1]))\n",
      "    \n",
      "    full_digit2_layer2_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_num_hidden1, FLAGS_num_labels + 1], stddev=0.1))\n",
      "    full_digit2_layer2_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_num_labels + 1]))\n",
      "    \n",
      "    full_digit3_layer2_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_num_hidden1, FLAGS_num_labels + 1], stddev=0.1))\n",
      "    full_digit3_layer2_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_num_labels + 1]))\n",
      "    \n",
      "    full_digit4_layer2_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_num_hidden1, FLAGS_num_labels + 1], stddev=0.1))\n",
      "    full_digit4_layer2_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_num_labels + 1]))\n",
      "    \n",
      "    \n",
      "    # OTHER VARIABLES\n",
      "    \n",
      "    global_step = tf.Variable(0)\n",
      "    \n",
      "      \n",
      "    # MODEL (TWO CONVOLUTIONAL AND TWO FULLY CONNECTED LAYERS)\n",
      "    \n",
      "    def model(data):\n",
      "        \n",
      "        # CONVOLUTION LAYERS\n",
      "        \n",
      "        conv = tf.nn.conv2d(data, conv_layer1_weights, [1, 1, 1, 1], padding='SAME')      #conv\n",
      "        hidden = tf.nn.relu(conv + conv_layer1_biases) \n",
      "        pooled = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')       #pool\n",
      "            \n",
      "        conv = tf.nn.conv2d(pooled, conv_layer2_weights, [1, 1, 1, 1], padding='SAME')    #conv\n",
      "        hidden = tf.nn.relu(conv + conv_layer2_biases)\n",
      "        pooled = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')       #pool\n",
      "                    \n",
      "        conv = tf.nn.conv2d(pooled, conv_layer3_weights, [1, 1, 1, 1], padding='SAME')    #conv\n",
      "        hidden = tf.nn.relu(conv + conv_layer3_biases)\n",
      "        hidden = tf.nn.dropout(hidden, FLAGS_prob1)\n",
      "        #pooled = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')       #pool\n",
      "               \n",
      "        shape = hidden.get_shape().as_list()        \n",
      "        reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
      "        \n",
      "        \n",
      "        # FULLY CONNECTED LAYERS FOR ALL DIGITS\n",
      "        \n",
      "        hidden = tf.nn.relu(tf.matmul(reshape, full_digit0_layer1_weights) + full_digit0_layer1_biases)\n",
      "        hidden = tf.nn.dropout(hidden, FLAGS_prob2)\n",
      "        digit_0 = tf.matmul(hidden, full_digit0_layer2_weights) + full_digit0_layer2_biases          \n",
      "        \n",
      "        hidden = tf.nn.relu(tf.matmul(reshape, full_digit1_layer1_weights) + full_digit1_layer1_biases) \n",
      "        hidden = tf.nn.dropout(hidden, FLAGS_prob2)\n",
      "        digit_1 = tf.matmul(hidden, full_digit1_layer2_weights) + full_digit1_layer2_biases          \n",
      "        \n",
      "        hidden = tf.nn.relu(tf.matmul(reshape, full_digit2_layer1_weights) + full_digit2_layer1_biases)     \n",
      "        hidden = tf.nn.dropout(hidden, FLAGS_prob2)\n",
      "        digit_2 = tf.matmul(hidden, full_digit2_layer2_weights) + full_digit2_layer2_biases          \n",
      "        \n",
      "        hidden = tf.nn.relu(tf.matmul(reshape, full_digit3_layer1_weights) + full_digit3_layer1_biases)\n",
      "        hidden = tf.nn.dropout(hidden, FLAGS_prob2)\n",
      "        digit_3 = tf.matmul(hidden, full_digit3_layer2_weights) + full_digit3_layer2_biases          \n",
      "        \n",
      "        hidden = tf.nn.relu(tf.matmul(reshape, full_digit4_layer1_weights) + full_digit4_layer1_biases)   \n",
      "        hidden = tf.nn.dropout(hidden, FLAGS_prob2)\n",
      "        digit_4 = tf.matmul(hidden, full_digit4_layer2_weights) + full_digit4_layer2_biases          \n",
      "              \n",
      "        return [digit_0, digit_1, digit_2, digit_3, digit_4]\n",
      "    \n",
      "    \n",
      "    \n",
      "    def softmax_joiner(logits):      \n",
      "        \n",
      "        return tf.transpose(tf.pack([tf.nn.softmax(logits[0]), tf.nn.softmax(logits[1]), \\\n",
      "                                     tf.nn.softmax(logits[2]), tf.nn.softmax(logits[3]), \\\n",
      "                                     tf.nn.softmax(logits[4])]), perm = [1,0,2])\n",
      "    \n",
      "  \n",
      "    # PREDICTIONS\n",
      "    \n",
      "    logits = model(tf_train_data) \n",
      "    \n",
      "    \n",
      "        \n",
      "    # LOSS FUNCTION\n",
      "    \n",
      "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits[0], tf_train_labels[:,0,:])) + \\\n",
      "           tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits[1], tf_train_labels[:,1,:])) + \\\n",
      "           tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits[2], tf_train_labels[:,2,:])) + \\\n",
      "           tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits[3], tf_train_labels[:,3,:])) + \\\n",
      "           tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits[4], tf_train_labels[:,4,:]))\n",
      "    \n",
      "    \n",
      "    # OPTIMIZING LOSS \n",
      "    \n",
      "    learning_rate = tf.train.exponential_decay(0.01, global_step, 1000, 0.9)\n",
      "    \n",
      "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)   # Use 0.001\n",
      "  \n",
      "    # PREDICTION FOR MINIBATCH TRAINING DATA\n",
      "    \n",
      "    train_prediction = softmax_joiner(logits)  \n",
      "                \n",
      "    \n",
      "    #PREDICTION FOR VALIDATION DATA   \n",
      "    \n",
      "    val_prediction0 = softmax_joiner(model(tf_val_data0))\n",
      "    val_prediction1 = softmax_joiner(model(tf_val_data1))\n",
      "    val_prediction2 = softmax_joiner(model(tf_val_data2))\n",
      "    val_prediction3 = softmax_joiner(model(tf_val_data3))\n",
      "    val_prediction4 = softmax_joiner(model(tf_val_data4))\n",
      "    val_prediction5 = softmax_joiner(model(tf_val_data5))\n",
      "    val_prediction6 = softmax_joiner(model(tf_val_data6))\n",
      "    val_prediction7 = softmax_joiner(model(tf_val_data7))\n",
      "    val_prediction8 = softmax_joiner(model(tf_val_data8))\n",
      "    val_prediction9 = softmax_joiner(model(tf_val_data9))\n",
      "    \n",
      "    #PREDICTION FOR TEST DATA\n",
      "    \n",
      "    test_prediction0 = softmax_joiner(model(tf_test_data0))\n",
      "    test_prediction1 = softmax_joiner(model(tf_test_data1))\n",
      "    test_prediction2 = softmax_joiner(model(tf_test_data2))\n",
      "    test_prediction3 = softmax_joiner(model(tf_test_data3))\n",
      "    test_prediction4 = softmax_joiner(model(tf_test_data4))\n",
      "    test_prediction5 = softmax_joiner(model(tf_test_data5))\n",
      "    test_prediction6 = softmax_joiner(model(tf_test_data6))\n",
      "    test_prediction7 = softmax_joiner(model(tf_test_data7))\n",
      "    test_prediction8 = softmax_joiner(model(tf_test_data8))\n",
      "    test_prediction9 = softmax_joiner(model(tf_test_data9))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# RUNNING THE ITERATIONS\n",
      "\n",
      "FLAGS_max_steps = 100001 #use 4001\n",
      "\n",
      "with tf.Session(graph=graph) as sess:\n",
      "    \n",
      "    init = tf.initialize_all_variables()\n",
      "    sess.run(init)\n",
      "    print(\"Initialized all variables\")\n",
      "    saver = tf.train.Saver()\n",
      "    \n",
      "    for step in range(FLAGS_max_steps):\n",
      "        \n",
      "        offset = (step * FLAGS_batch_size) % (FLAGS_train_size - FLAGS_batch_size)\n",
      "    \n",
      "        # MINIBATCH\n",
      "        \n",
      "        batch_data = train_data[offset:(offset + FLAGS_batch_size), :, :, :]\n",
      "        batch_labels = train_1hot_labels[offset:(offset + FLAGS_batch_size), :, :]\n",
      "        \n",
      "        \n",
      "        # FEED GRAPH\n",
      "        \n",
      "        feed_dict = {tf_train_data : batch_data, tf_train_labels : batch_labels}\n",
      "        _, l, predictions = sess.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
      "        \n",
      "        \n",
      "        # PERIODIC EVALUATION\n",
      "        \n",
      "        if (step % 1000 == 0):\n",
      "            print(\"\\nMinibatch loss at step %d: %f\" % (step, l))\n",
      "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
      "            \n",
      "            val_accuracy = (accuracy(val_prediction0.eval(), val_1hot_labels[0 * (FLAGS_val_size/10): 1 * (FLAGS_val_size/10)]) + \\\n",
      "                            accuracy(val_prediction1.eval(), val_1hot_labels[1 * (FLAGS_val_size/10): 2 * (FLAGS_val_size/10)]) + \\\n",
      "                            accuracy(val_prediction2.eval(), val_1hot_labels[2 * (FLAGS_val_size/10): 3 * (FLAGS_val_size/10)]) + \\\n",
      "                            accuracy(val_prediction3.eval(), val_1hot_labels[3 * (FLAGS_val_size/10): 4 * (FLAGS_val_size/10)]) + \\\n",
      "                            accuracy(val_prediction4.eval(), val_1hot_labels[4 * (FLAGS_val_size/10): 5 * (FLAGS_val_size/10)]) + \\\n",
      "                            accuracy(val_prediction5.eval(), val_1hot_labels[5 * (FLAGS_val_size/10): 6 * (FLAGS_val_size/10)]) + \\\n",
      "                            accuracy(val_prediction6.eval(), val_1hot_labels[6 * (FLAGS_val_size/10): 7 * (FLAGS_val_size/10)]) + \\\n",
      "                            accuracy(val_prediction7.eval(), val_1hot_labels[7 * (FLAGS_val_size/10): 8 * (FLAGS_val_size/10)]) + \\\n",
      "                            accuracy(val_prediction8.eval(), val_1hot_labels[8 * (FLAGS_val_size/10): 9 * (FLAGS_val_size/10)]) + \\\n",
      "                            accuracy(val_prediction9.eval(), val_1hot_labels[9 * (FLAGS_val_size/10):10 * (FLAGS_val_size/10)])) / 10.0\n",
      "            \n",
      "            print(\"Validation accuracy: %.1f%%\" % val_accuracy)               \n",
      "         \n",
      "\n",
      "    # FINAL EVALUATION    \n",
      "            \n",
      "    test_accuracy = (accuracy(test_prediction0.eval(), test_1hot_labels[0 * (FLAGS_test_size/10): 1 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction1.eval(), test_1hot_labels[1 * (FLAGS_test_size/10): 2 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction2.eval(), test_1hot_labels[2 * (FLAGS_test_size/10): 3 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction3.eval(), test_1hot_labels[3 * (FLAGS_test_size/10): 4 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction4.eval(), test_1hot_labels[4 * (FLAGS_test_size/10): 5 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction5.eval(), test_1hot_labels[5 * (FLAGS_test_size/10): 6 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction6.eval(), test_1hot_labels[6 * (FLAGS_test_size/10): 7 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction7.eval(), test_1hot_labels[7 * (FLAGS_test_size/10): 8 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction8.eval(), test_1hot_labels[8 * (FLAGS_test_size/10): 9 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction9.eval(), test_1hot_labels[9 * (FLAGS_test_size/10):10 * (FLAGS_test_size/10)])) / 10.0  \n",
      "    \n",
      "    print(\"\\nTest accuracy: %.1f%%\" % test_accuracy)\n",
      "    \n",
      "    # SAVE MODEL FOR LATER USE\n",
      "    \n",
      "    save_path = saver.save(sess, \"/home/shilpak/ML_Playground/deep-learning-capstone/model1.ckpt\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initialized all variables\n",
        "\n",
        "Minibatch loss at step 0: 75.341476"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 0.0%\n",
        "Validation accuracy: 0.8%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 1000: 6.523889"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 0.0%\n",
        "Validation accuracy: 0.6%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 2000: 6.433924"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 1.6%\n",
        "Validation accuracy: 1.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 3000: 6.370369"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 1.6%\n",
        "Validation accuracy: 2.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 4000: 6.174133"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 1.6%\n",
        "Validation accuracy: 2.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 5000: 5.263499"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 3.1%\n",
        "Validation accuracy: 5.7%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 6000: 5.259164"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 7.8%\n",
        "Validation accuracy: 8.3%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 7000: 4.401332"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 21.9%\n",
        "Validation accuracy: 12.8%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 8000: 3.866110"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 21.9%\n",
        "Validation accuracy: 16.8%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 9000: 4.540416"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 20.3%\n",
        "Validation accuracy: 21.7%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 10000: 4.516842"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 20.3%\n",
        "Validation accuracy: 22.3%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 11000: 4.117260"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 29.7%\n",
        "Validation accuracy: 26.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 12000: 3.368613"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 37.5%\n",
        "Validation accuracy: 29.4%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 13000: 3.962019"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 25.0%\n",
        "Validation accuracy: 31.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 14000: 3.428946"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 23.4%\n",
        "Validation accuracy: 33.1%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 15000: 3.243369"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 40.6%\n",
        "Validation accuracy: 35.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 16000: 2.656627"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 40.6%\n",
        "Validation accuracy: 39.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 17000: 2.903591"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 46.9%\n",
        "Validation accuracy: 40.1%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 18000: 2.876872"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 32.8%\n",
        "Validation accuracy: 41.4%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 19000: 2.775783"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 45.3%\n",
        "Validation accuracy: 42.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 20000: 2.692190"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 43.8%\n",
        "Validation accuracy: 43.8%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 21000: 2.124056"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 54.7%\n",
        "Validation accuracy: 46.1%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 22000: 2.811691"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 32.8%\n",
        "Validation accuracy: 47.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 23000: 2.594359"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 43.8%\n",
        "Validation accuracy: 48.4%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 24000: 2.344620"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 48.4%\n",
        "Validation accuracy: 49.7%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 25000: 2.443668"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 51.6%\n",
        "Validation accuracy: 51.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 26000: 2.128511"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 54.7%\n",
        "Validation accuracy: 51.8%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 27000: 3.218248"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 54.7%\n",
        "Validation accuracy: 51.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 28000: 2.278036"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 48.4%\n",
        "Validation accuracy: 53.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 29000: 2.269028"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 45.3%\n",
        "Validation accuracy: 54.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 30000: 2.914073"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 57.8%\n",
        "Validation accuracy: 54.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 31000: 1.887795"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 62.5%\n",
        "Validation accuracy: 56.1%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 32000: 2.240855"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 56.2%\n",
        "Validation accuracy: 57.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 33000: 2.467829"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 48.4%\n",
        "Validation accuracy: 57.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 34000: 1.632527"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 53.1%\n",
        "Validation accuracy: 58.3%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 35000: 2.057612"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 54.7%\n",
        "Validation accuracy: 57.6%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 36000: 1.873079"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 59.4%\n",
        "Validation accuracy: 58.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 37000: 2.061900"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 54.7%\n",
        "Validation accuracy: 59.4%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 38000: 1.741408"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 59.4%\n",
        "Validation accuracy: 60.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 39000: 2.214767"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 54.7%\n",
        "Validation accuracy: 60.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 40000: 1.480162"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 64.1%\n",
        "Validation accuracy: 60.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 41000: 1.520045"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 68.8%\n",
        "Validation accuracy: 61.8%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 42000: 1.322514"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 67.2%\n",
        "Validation accuracy: 63.4%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 43000: 1.411376"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 65.6%\n",
        "Validation accuracy: 62.8%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 44000: 1.683524"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 65.6%\n",
        "Validation accuracy: 63.1%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 45000: 1.539957"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 56.2%\n",
        "Validation accuracy: 63.6%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 46000: 1.819626"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 62.5%\n",
        "Validation accuracy: 64.8%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 47000: 1.792251"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 64.1%\n",
        "Validation accuracy: 63.4%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 48000: 1.491874"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 71.9%\n",
        "Validation accuracy: 64.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 49000: 1.751354"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 67.2%\n",
        "Validation accuracy: 64.8%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 50000: 1.704797"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 62.5%\n",
        "Validation accuracy: 66.3%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 51000: 0.853447"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 73.4%\n",
        "Validation accuracy: 66.8%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 52000: 1.672522"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 54.7%\n",
        "Validation accuracy: 66.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 53000: 1.645275"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 56.2%\n",
        "Validation accuracy: 67.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 54000: 1.472781"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 67.2%\n",
        "Validation accuracy: 66.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 55000: 1.235545"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 70.3%\n",
        "Validation accuracy: 68.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 56000: 1.752992"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 62.5%\n",
        "Validation accuracy: 66.6%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 57000: 1.536065"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 67.2%\n",
        "Validation accuracy: 68.6%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 58000: 1.655557"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 67.2%\n",
        "Validation accuracy: 68.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 59000: 1.625048"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 62.5%\n",
        "Validation accuracy: 67.3%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 60000: 1.613515"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 65.6%\n",
        "Validation accuracy: 69.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 61000: 1.612532"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 65.6%\n",
        "Validation accuracy: 69.1%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 62000: 2.009910"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 60.9%\n",
        "Validation accuracy: 68.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 63000: 1.419068"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 64.1%\n",
        "Validation accuracy: 68.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 64000: 1.010699"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 76.6%\n",
        "Validation accuracy: 70.4%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 65000: 1.357969"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 64.1%\n",
        "Validation accuracy: 69.6%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 66000: 1.488705"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 59.4%\n",
        "Validation accuracy: 70.4%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 67000: 1.273173"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 71.9%\n",
        "Validation accuracy: 70.8%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 68000: 1.272976"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 71.9%\n",
        "Validation accuracy: 71.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 69000: 0.739801"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 84.4%\n",
        "Validation accuracy: 71.8%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 70000: 1.293379"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 78.1%\n",
        "Validation accuracy: 72.7%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 71000: 1.290053"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 78.1%\n",
        "Validation accuracy: 72.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 72000: 1.627915"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 82.8%\n",
        "Validation accuracy: 71.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 73000: 1.343327"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 71.9%\n",
        "Validation accuracy: 72.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 74000: 0.877031"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 73.4%\n",
        "Validation accuracy: 73.3%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 75000: 1.378432"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 70.3%\n",
        "Validation accuracy: 72.6%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 76000: 0.714109"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 84.4%\n",
        "Validation accuracy: 73.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 77000: 1.008836"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 70.3%\n",
        "Validation accuracy: 72.7%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 78000: 1.101157"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 64.1%\n",
        "Validation accuracy: 72.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 79000: 1.159454"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 67.2%\n",
        "Validation accuracy: 72.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 80000: 1.503730"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 65.6%\n",
        "Validation accuracy: 73.3%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 81000: 1.265189"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 76.6%\n",
        "Validation accuracy: 73.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 82000: 0.791400"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 78.1%\n",
        "Validation accuracy: 73.7%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 83000: 1.313525"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 70.3%\n",
        "Validation accuracy: 73.7%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 84000: 1.318017"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 78.1%\n",
        "Validation accuracy: 73.4%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 85000: 1.035858"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 73.4%\n",
        "Validation accuracy: 73.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 86000: 1.199381"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 68.8%\n",
        "Validation accuracy: 73.6%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 87000: 1.785773"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 65.6%\n",
        "Validation accuracy: 74.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 88000: 1.099130"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 79.7%\n",
        "Validation accuracy: 74.7%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 89000: 0.929339"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 78.1%\n",
        "Validation accuracy: 74.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 90000: 0.964648"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 76.6%\n",
        "Validation accuracy: 74.6%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 91000: 1.001905"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 73.4%\n",
        "Validation accuracy: 75.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 92000: 1.179228"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 67.2%\n",
        "Validation accuracy: 74.8%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 93000: 1.066826"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 71.9%\n",
        "Validation accuracy: 75.3%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 94000: 1.088328"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 71.9%\n",
        "Validation accuracy: 74.8%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 95000: 1.122741"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 78.1%\n",
        "Validation accuracy: 75.6%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 96000: 1.250553"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 71.9%\n",
        "Validation accuracy: 77.1%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 97000: 1.049160"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 78.1%\n",
        "Validation accuracy: 75.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 98000: 1.253621"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 60.9%\n",
        "Validation accuracy: 74.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 99000: 0.617195"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 84.4%\n",
        "Validation accuracy: 76.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 100000: 1.239412"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 73.4%\n",
        "Validation accuracy: 76.6%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Test accuracy: 56.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# RUNNING THE ITERATIONS AGAIN WITH THE TRAINED MODEL\n",
      "\n",
      "FLAGS_max_steps = 50001 \n",
      "\n",
      "with tf.Session(graph=graph) as sess:\n",
      "    \n",
      "    saver = tf.train.Saver()\n",
      "    saver.restore(sess, \"/home/shilpak/ML_Playground/deep-learning-capstone/model1.ckpt\")\n",
      "    print(\"Model restored. Ready for more training!\")\n",
      "    \n",
      "    for step in range(FLAGS_max_steps):\n",
      "        \n",
      "        offset = (step * FLAGS_batch_size) % (FLAGS_train_size - FLAGS_batch_size)\n",
      "    \n",
      "        # MINIBATCH\n",
      "        \n",
      "        batch_data = train_data[offset:(offset + FLAGS_batch_size), :, :, :]\n",
      "        batch_labels = train_1hot_labels[offset:(offset + FLAGS_batch_size), :, :]\n",
      "        \n",
      "        \n",
      "        # FEED GRAPH\n",
      "        \n",
      "        feed_dict = {tf_train_data : batch_data, tf_train_labels : batch_labels}\n",
      "        _, l, predictions = sess.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
      "        \n",
      "        \n",
      "        # PERIODIC EVALUATION\n",
      "        \n",
      "        if (step % 1000 == 0):\n",
      "            print(\"\\nMinibatch loss at step %d: %f\" % (step, l))\n",
      "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
      "            \n",
      "            val_accuracy = (accuracy(val_prediction0.eval(), val_1hot_labels[0 * (FLAGS_val_size/10): 1 * (FLAGS_val_size/10)]) + \\\n",
      "                            accuracy(val_prediction1.eval(), val_1hot_labels[1 * (FLAGS_val_size/10): 2 * (FLAGS_val_size/10)]) + \\\n",
      "                            accuracy(val_prediction2.eval(), val_1hot_labels[2 * (FLAGS_val_size/10): 3 * (FLAGS_val_size/10)]) + \\\n",
      "                            accuracy(val_prediction3.eval(), val_1hot_labels[3 * (FLAGS_val_size/10): 4 * (FLAGS_val_size/10)]) + \\\n",
      "                            accuracy(val_prediction4.eval(), val_1hot_labels[4 * (FLAGS_val_size/10): 5 * (FLAGS_val_size/10)]) + \\\n",
      "                            accuracy(val_prediction5.eval(), val_1hot_labels[5 * (FLAGS_val_size/10): 6 * (FLAGS_val_size/10)]) + \\\n",
      "                            accuracy(val_prediction6.eval(), val_1hot_labels[6 * (FLAGS_val_size/10): 7 * (FLAGS_val_size/10)]) + \\\n",
      "                            accuracy(val_prediction7.eval(), val_1hot_labels[7 * (FLAGS_val_size/10): 8 * (FLAGS_val_size/10)]) + \\\n",
      "                            accuracy(val_prediction8.eval(), val_1hot_labels[8 * (FLAGS_val_size/10): 9 * (FLAGS_val_size/10)]) + \\\n",
      "                            accuracy(val_prediction9.eval(), val_1hot_labels[9 * (FLAGS_val_size/10):10 * (FLAGS_val_size/10)])) / 10.0\n",
      "            \n",
      "            print(\"Validation accuracy: %.1f%%\" % val_accuracy)               \n",
      "         \n",
      "\n",
      "    # FINAL EVALUATION    \n",
      "            \n",
      "    test_accuracy = (accuracy(test_prediction0.eval(), test_1hot_labels[0 * (FLAGS_test_size/10): 1 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction1.eval(), test_1hot_labels[1 * (FLAGS_test_size/10): 2 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction2.eval(), test_1hot_labels[2 * (FLAGS_test_size/10): 3 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction3.eval(), test_1hot_labels[3 * (FLAGS_test_size/10): 4 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction4.eval(), test_1hot_labels[4 * (FLAGS_test_size/10): 5 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction5.eval(), test_1hot_labels[5 * (FLAGS_test_size/10): 6 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction6.eval(), test_1hot_labels[6 * (FLAGS_test_size/10): 7 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction7.eval(), test_1hot_labels[7 * (FLAGS_test_size/10): 8 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction8.eval(), test_1hot_labels[8 * (FLAGS_test_size/10): 9 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction9.eval(), test_1hot_labels[9 * (FLAGS_test_size/10):10 * (FLAGS_test_size/10)])) / 10.0  \n",
      "    \n",
      "    print(\"\\nTest accuracy: %.1f%%\" % test_accuracy)\n",
      "    \n",
      "    # SAVE MODEL FOR LATER USE\n",
      "    \n",
      "    save_path = saver.save(sess, \"/home/shilpak/ML_Playground/deep-learning-capstone/model1.ckpt\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Model restored. Ready for more training!\n",
        "\n",
        "Minibatch loss at step 0: 1.096560"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 68.8%\n",
        "Validation accuracy: 76.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 1000: 0.634317"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 84.4%\n",
        "Validation accuracy: 75.8%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 2000: 1.083028"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 78.1%\n",
        "Validation accuracy: 76.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 3000: 1.138028"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 75.0%\n",
        "Validation accuracy: 77.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 4000: 1.038792"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 73.4%\n",
        "Validation accuracy: 76.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 5000: 1.020684"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 84.4%\n",
        "Validation accuracy: 77.4%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 6000: 1.152781"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 76.6%\n",
        "Validation accuracy: 76.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 7000: 0.857286"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 78.1%\n",
        "Validation accuracy: 76.6%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 8000: 0.984564"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 79.7%\n",
        "Validation accuracy: 77.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 9000: 1.625860"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 67.2%\n",
        "Validation accuracy: 77.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 10000: 1.438432"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 75.0%\n",
        "Validation accuracy: 77.6%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 11000: 1.320038"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 73.4%\n",
        "Validation accuracy: 77.4%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 12000: 0.669672"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 81.2%\n",
        "Validation accuracy: 77.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 13000: 1.016253"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 75.0%\n",
        "Validation accuracy: 76.8%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 14000: 1.102664"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 71.9%\n",
        "Validation accuracy: 78.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 15000: 1.128182"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 78.1%\n",
        "Validation accuracy: 77.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 16000: 0.675480"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 82.8%\n",
        "Validation accuracy: 77.8%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 17000: 1.330382"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 81.2%\n",
        "Validation accuracy: 78.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 18000: 0.980059"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 76.6%\n",
        "Validation accuracy: 78.3%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 19000: 1.113132"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 75.0%\n",
        "Validation accuracy: 77.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 20000: 0.528745"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 85.9%\n",
        "Validation accuracy: 78.3%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 21000: 0.766492"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 82.8%\n",
        "Validation accuracy: 78.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 22000: 0.802610"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 75.0%\n",
        "Validation accuracy: 77.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 23000: 1.158823"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 71.9%\n",
        "Validation accuracy: 77.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 24000: 0.810466"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 76.6%\n",
        "Validation accuracy: 78.8%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 25000: 0.718871"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 75.0%\n",
        "Validation accuracy: 78.6%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 26000: 0.876781"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 75.0%\n",
        "Validation accuracy: 78.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 27000: 1.416259"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 76.6%\n",
        "Validation accuracy: 79.4%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 28000: 1.176932"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 81.2%\n",
        "Validation accuracy: 78.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 29000: 0.706568"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 79.7%\n",
        "Validation accuracy: 78.4%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 30000: 1.652275"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 75.0%\n",
        "Validation accuracy: 78.4%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 31000: 0.526534"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 85.9%\n",
        "Validation accuracy: 78.7%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 32000: 0.873226"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 82.8%\n",
        "Validation accuracy: 79.1%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 33000: 1.391456"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 76.6%\n",
        "Validation accuracy: 79.3%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 34000: 0.617460"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 82.8%\n",
        "Validation accuracy: 79.1%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 35000: 0.992634"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 85.9%\n",
        "Validation accuracy: 79.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 36000: 0.907452"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 79.7%\n",
        "Validation accuracy: 78.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 37000: 0.749813"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 79.7%\n",
        "Validation accuracy: 78.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 38000: 0.583161"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 82.8%\n",
        "Validation accuracy: 78.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 39000: 1.174571"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 76.6%\n",
        "Validation accuracy: 79.4%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 40000: 0.855226"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 81.2%\n",
        "Validation accuracy: 79.1%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 41000: 0.558114"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 89.1%\n",
        "Validation accuracy: 79.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 42000: 0.677613"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 75.0%\n",
        "Validation accuracy: 79.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 43000: 0.700041"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 84.4%\n",
        "Validation accuracy: 79.6%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 44000: 0.890656"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 81.2%\n",
        "Validation accuracy: 79.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 45000: 0.725248"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 76.6%\n",
        "Validation accuracy: 80.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 46000: 0.655078"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 87.5%\n",
        "Validation accuracy: 79.7%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 47000: 0.868039"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 81.2%\n",
        "Validation accuracy: 79.1%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 48000: 0.741664"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 85.9%\n",
        "Validation accuracy: 79.7%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 49000: 1.171955"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 73.4%\n",
        "Validation accuracy: 80.3%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Minibatch loss at step 50000: 1.049816"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 81.2%\n",
        "Validation accuracy: 80.3%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Test accuracy: 60.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# BUILDING THE GRAPH WITHOUT THE DROPOUTS\n",
      "\n",
      "FLAGS_image_size = 32\n",
      "FLAGS_batch_size = 64\n",
      "FLAGS_patch_size = 5\n",
      "\n",
      "FLAGS_depth1 = 64\n",
      "FLAGS_depth2 = 64\n",
      "FLAGS_depth3 = 64\n",
      "\n",
      "FLAGS_num_hidden1 = 64\n",
      "\n",
      "FLAGS_num_channels = 1\n",
      "\n",
      "\n",
      "graph = tf.Graph()\n",
      "\n",
      "with graph.as_default():  \n",
      "    \n",
      "    \n",
      "    # INPUT DATA\n",
      "    \n",
      "    tf_train_data = tf.placeholder(\n",
      "        tf.float32, shape=(FLAGS_batch_size, FLAGS_image_size, FLAGS_image_size, FLAGS_num_channels))\n",
      "    \n",
      "    tf_train_labels = tf.placeholder(tf.float32, shape=(FLAGS_batch_size, 5, FLAGS_num_labels + 1))\n",
      "        \n",
      "    \n",
      "    tf_val_data0 = tf.constant(val_data[0 * (FLAGS_val_size/10): 1 * (FLAGS_val_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_val_data1 = tf.constant(val_data[1 * (FLAGS_val_size/10): 2 * (FLAGS_val_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_val_data2 = tf.constant(val_data[2 * (FLAGS_val_size/10): 3 * (FLAGS_val_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_val_data3 = tf.constant(val_data[3 * (FLAGS_val_size/10): 4 * (FLAGS_val_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_val_data4 = tf.constant(val_data[4 * (FLAGS_val_size/10): 5 * (FLAGS_val_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_val_data5 = tf.constant(val_data[5 * (FLAGS_val_size/10): 6 * (FLAGS_val_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_val_data6 = tf.constant(val_data[6 * (FLAGS_val_size/10): 7 * (FLAGS_val_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_val_data7 = tf.constant(val_data[7 * (FLAGS_val_size/10): 8 * (FLAGS_val_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_val_data8 = tf.constant(val_data[8 * (FLAGS_val_size/10): 9 * (FLAGS_val_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_val_data9 = tf.constant(val_data[9 * (FLAGS_val_size/10):10 * (FLAGS_val_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "        \n",
      "    \n",
      "    tf_test_data0 = tf.constant(test_data[0 * (FLAGS_test_size/10): 1 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_test_data1 = tf.constant(test_data[1 * (FLAGS_test_size/10): 2 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_test_data2 = tf.constant(test_data[2 * (FLAGS_test_size/10): 3 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_test_data3 = tf.constant(test_data[3 * (FLAGS_test_size/10): 4 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_test_data4 = tf.constant(test_data[4 * (FLAGS_test_size/10): 5 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_test_data5 = tf.constant(test_data[5 * (FLAGS_test_size/10): 6 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_test_data6 = tf.constant(test_data[6 * (FLAGS_test_size/10): 7 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_test_data7 = tf.constant(test_data[7 * (FLAGS_test_size/10): 8 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_test_data8 = tf.constant(test_data[8 * (FLAGS_test_size/10): 9 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_test_data9 = tf.constant(test_data[9 * (FLAGS_test_size/10):10 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    \n",
      "    tf_train_data0 = tf.constant(train_data[0 * (FLAGS_test_size/10): 1 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_train_data1 = tf.constant(train_data[1 * (FLAGS_test_size/10): 2 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_train_data2 = tf.constant(train_data[2 * (FLAGS_test_size/10): 3 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_train_data3 = tf.constant(train_data[3 * (FLAGS_test_size/10): 4 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_train_data4 = tf.constant(train_data[4 * (FLAGS_test_size/10): 5 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_train_data5 = tf.constant(train_data[5 * (FLAGS_test_size/10): 6 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_train_data6 = tf.constant(train_data[6 * (FLAGS_test_size/10): 7 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_train_data7 = tf.constant(train_data[7 * (FLAGS_test_size/10): 8 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_train_data8 = tf.constant(train_data[8 * (FLAGS_test_size/10): 9 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    tf_train_data9 = tf.constant(train_data[9 * (FLAGS_test_size/10):10 * (FLAGS_test_size/10) ,: ,: ,: ].astype(np.float32))\n",
      "    \n",
      "    \n",
      "    # VARIABLES INITIALIZATION (TWO CONVOLUTION LAYERS WITH SHARED WEIGHTS)\n",
      "    \n",
      "    conv_layer1_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_patch_size, FLAGS_patch_size, FLAGS_num_channels, FLAGS_depth1], stddev=0.1))\n",
      "    conv_layer1_biases = tf.Variable(tf.zeros([FLAGS_depth1]))\n",
      "    \n",
      "    conv_layer2_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_patch_size, FLAGS_patch_size, FLAGS_depth1, FLAGS_depth2], stddev=0.1))\n",
      "    conv_layer2_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_depth2]))\n",
      "    \n",
      "    conv_layer3_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_patch_size, FLAGS_patch_size, FLAGS_depth2, FLAGS_depth3], stddev=0.1))\n",
      "    conv_layer3_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_depth3]))\n",
      "   \n",
      "    \n",
      "    # VARIABLES INITIALIZATION (FIRST FULLY CONNECTED LAYER WITH NON_SHARED WEIGHTS)\n",
      "    \n",
      "    full_digit0_layer1_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_image_size // 4 * FLAGS_image_size // 4 * FLAGS_depth3, FLAGS_num_hidden1], stddev=0.1))\n",
      "    full_digit0_layer1_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_num_hidden1]))\n",
      "    \n",
      "    full_digit1_layer1_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_image_size // 4 * FLAGS_image_size // 4 * FLAGS_depth3, FLAGS_num_hidden1], stddev=0.1))\n",
      "    full_digit1_layer1_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_num_hidden1]))\n",
      "    \n",
      "    full_digit2_layer1_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_image_size // 4 * FLAGS_image_size // 4 * FLAGS_depth3, FLAGS_num_hidden1], stddev=0.1))\n",
      "    full_digit2_layer1_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_num_hidden1]))\n",
      "    \n",
      "    full_digit3_layer1_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_image_size // 4 * FLAGS_image_size // 4 * FLAGS_depth3, FLAGS_num_hidden1], stddev=0.1))\n",
      "    full_digit3_layer1_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_num_hidden1]))\n",
      "    \n",
      "    full_digit4_layer1_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_image_size // 4 * FLAGS_image_size // 4 * FLAGS_depth3, FLAGS_num_hidden1], stddev=0.1))\n",
      "    full_digit4_layer1_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_num_hidden1]))\n",
      "    \n",
      "    \n",
      "    \n",
      "    # VARIABLES INITIALIZATION (SECOND FULLY CONNECTED LAYER WITH NON_SHARED WEIGHTS)\n",
      "    \n",
      "    full_digit0_layer2_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_num_hidden1, FLAGS_num_labels + 1], stddev=0.1))\n",
      "    full_digit0_layer2_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_num_labels + 1]))\n",
      "    \n",
      "    full_digit1_layer2_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_num_hidden1, FLAGS_num_labels + 1], stddev=0.1))\n",
      "    full_digit1_layer2_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_num_labels + 1]))\n",
      "    \n",
      "    full_digit2_layer2_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_num_hidden1, FLAGS_num_labels + 1], stddev=0.1))\n",
      "    full_digit2_layer2_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_num_labels + 1]))\n",
      "    \n",
      "    full_digit3_layer2_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_num_hidden1, FLAGS_num_labels + 1], stddev=0.1))\n",
      "    full_digit3_layer2_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_num_labels + 1]))\n",
      "    \n",
      "    full_digit4_layer2_weights = tf.Variable(tf.truncated_normal(\n",
      "          [FLAGS_num_hidden1, FLAGS_num_labels + 1], stddev=0.1))\n",
      "    full_digit4_layer2_biases = tf.Variable(tf.constant(1.0, shape=[FLAGS_num_labels + 1]))\n",
      "    \n",
      "    \n",
      "    # OTHER VARIABLES\n",
      "    \n",
      "    global_step = tf.Variable(0)\n",
      "    \n",
      "      \n",
      "    # MODEL (TWO CONVOLUTIONAL AND TWO FULLY CONNECTED LAYERS)\n",
      "    \n",
      "    def model(data):\n",
      "        \n",
      "        # CONVOLUTION LAYERS\n",
      "        \n",
      "        conv = tf.nn.conv2d(data, conv_layer1_weights, [1, 1, 1, 1], padding='SAME')      #conv\n",
      "        hidden = tf.nn.relu(conv + conv_layer1_biases) \n",
      "        pooled = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')       #pool\n",
      "            \n",
      "        conv = tf.nn.conv2d(pooled, conv_layer2_weights, [1, 1, 1, 1], padding='SAME')    #conv\n",
      "        hidden = tf.nn.relu(conv + conv_layer2_biases)\n",
      "        pooled = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')       #pool\n",
      "                    \n",
      "        conv = tf.nn.conv2d(pooled, conv_layer3_weights, [1, 1, 1, 1], padding='SAME')    #conv\n",
      "        hidden = tf.nn.relu(conv + conv_layer3_biases)\n",
      "        #hidden = tf.nn.dropout(hidden, FLAGS_prob1)\n",
      "        #pooled = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')       #pool\n",
      "               \n",
      "        shape = hidden.get_shape().as_list()        \n",
      "        reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
      "        \n",
      "        \n",
      "        # FULLY CONNECTED LAYERS FOR ALL DIGITS\n",
      "        \n",
      "        hidden = tf.nn.relu(tf.matmul(reshape, full_digit0_layer1_weights) + full_digit0_layer1_biases)\n",
      "        #hidden = tf.nn.dropout(hidden, FLAGS_prob2)\n",
      "        digit_0 = tf.matmul(hidden, full_digit0_layer2_weights) + full_digit0_layer2_biases          \n",
      "        \n",
      "        hidden = tf.nn.relu(tf.matmul(reshape, full_digit1_layer1_weights) + full_digit1_layer1_biases) \n",
      "        #hidden = tf.nn.dropout(hidden, FLAGS_prob2)\n",
      "        digit_1 = tf.matmul(hidden, full_digit1_layer2_weights) + full_digit1_layer2_biases          \n",
      "        \n",
      "        hidden = tf.nn.relu(tf.matmul(reshape, full_digit2_layer1_weights) + full_digit2_layer1_biases)     \n",
      "        #hidden = tf.nn.dropout(hidden, FLAGS_prob2)\n",
      "        digit_2 = tf.matmul(hidden, full_digit2_layer2_weights) + full_digit2_layer2_biases          \n",
      "        \n",
      "        hidden = tf.nn.relu(tf.matmul(reshape, full_digit3_layer1_weights) + full_digit3_layer1_biases)\n",
      "        #hidden = tf.nn.dropout(hidden, FLAGS_prob2)\n",
      "        digit_3 = tf.matmul(hidden, full_digit3_layer2_weights) + full_digit3_layer2_biases          \n",
      "        \n",
      "        hidden = tf.nn.relu(tf.matmul(reshape, full_digit4_layer1_weights) + full_digit4_layer1_biases)   \n",
      "        #hidden = tf.nn.dropout(hidden, FLAGS_prob2)\n",
      "        digit_4 = tf.matmul(hidden, full_digit4_layer2_weights) + full_digit4_layer2_biases          \n",
      "              \n",
      "        return [digit_0, digit_1, digit_2, digit_3, digit_4]\n",
      "    \n",
      "    \n",
      "    \n",
      "    def softmax_joiner(logits):      \n",
      "        \n",
      "        return tf.transpose(tf.pack([tf.nn.softmax(logits[0]), tf.nn.softmax(logits[1]), \\\n",
      "                                     tf.nn.softmax(logits[2]), tf.nn.softmax(logits[3]), \\\n",
      "                                     tf.nn.softmax(logits[4])]), perm = [1,0,2])\n",
      "    \n",
      "  \n",
      "    # PREDICTIONS\n",
      "    \n",
      "    logits = model(tf_train_data) \n",
      "    \n",
      "    \n",
      "        \n",
      "    # LOSS FUNCTION\n",
      "    \n",
      "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits[0], tf_train_labels[:,0,:])) + \\\n",
      "           tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits[1], tf_train_labels[:,1,:])) + \\\n",
      "           tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits[2], tf_train_labels[:,2,:])) + \\\n",
      "           tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits[3], tf_train_labels[:,3,:])) + \\\n",
      "           tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits[4], tf_train_labels[:,4,:]))\n",
      "    \n",
      "    \n",
      "    # OPTIMIZING LOSS \n",
      "    \n",
      "    learning_rate = tf.train.exponential_decay(0.01, global_step, 1000, 0.9)\n",
      "    \n",
      "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)   # Use 0.001\n",
      "  \n",
      "    # PREDICTION FOR MINIBATCH TRAINING DATA\n",
      "    \n",
      "    train_prediction = softmax_joiner(logits)  \n",
      "                \n",
      "    \n",
      "    #PREDICTION FOR VALIDATION DATA   \n",
      "    \n",
      "    val_prediction0 = softmax_joiner(model(tf_val_data0))\n",
      "    val_prediction1 = softmax_joiner(model(tf_val_data1))\n",
      "    val_prediction2 = softmax_joiner(model(tf_val_data2))\n",
      "    val_prediction3 = softmax_joiner(model(tf_val_data3))\n",
      "    val_prediction4 = softmax_joiner(model(tf_val_data4))\n",
      "    val_prediction5 = softmax_joiner(model(tf_val_data5))\n",
      "    val_prediction6 = softmax_joiner(model(tf_val_data6))\n",
      "    val_prediction7 = softmax_joiner(model(tf_val_data7))\n",
      "    val_prediction8 = softmax_joiner(model(tf_val_data8))\n",
      "    val_prediction9 = softmax_joiner(model(tf_val_data9))\n",
      "    \n",
      "    #PREDICTION FOR TEST DATA\n",
      "    \n",
      "    test_prediction0 = softmax_joiner(model(tf_test_data0))\n",
      "    test_prediction1 = softmax_joiner(model(tf_test_data1))\n",
      "    test_prediction2 = softmax_joiner(model(tf_test_data2))\n",
      "    test_prediction3 = softmax_joiner(model(tf_test_data3))\n",
      "    test_prediction4 = softmax_joiner(model(tf_test_data4))\n",
      "    test_prediction5 = softmax_joiner(model(tf_test_data5))\n",
      "    test_prediction6 = softmax_joiner(model(tf_test_data6))\n",
      "    test_prediction7 = softmax_joiner(model(tf_test_data7))\n",
      "    test_prediction8 = softmax_joiner(model(tf_test_data8))\n",
      "    test_prediction9 = softmax_joiner(model(tf_test_data9))\n",
      "    \n",
      "    #PREDICTION FOR TEST DATA\n",
      "    \n",
      "    train_prediction0 = softmax_joiner(model(tf_train_data0))\n",
      "    train_prediction1 = softmax_joiner(model(tf_train_data1))\n",
      "    train_prediction2 = softmax_joiner(model(tf_train_data2))\n",
      "    train_prediction3 = softmax_joiner(model(tf_train_data3))\n",
      "    train_prediction4 = softmax_joiner(model(tf_train_data4))\n",
      "    train_prediction5 = softmax_joiner(model(tf_train_data5))\n",
      "    train_prediction6 = softmax_joiner(model(tf_train_data6))\n",
      "    train_prediction7 = softmax_joiner(model(tf_train_data7))\n",
      "    train_prediction8 = softmax_joiner(model(tf_train_data8))\n",
      "    train_prediction9 = softmax_joiner(model(tf_train_data9))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with tf.Session(graph=graph) as sess:\n",
      "    \n",
      "    saver = tf.train.Saver()\n",
      "    saver.restore(sess, \"/home/shilpak/ML_Playground/deep-learning-capstone/model1.ckpt\")\n",
      "    print(\"Model restored.\")\n",
      "    \n",
      "    train_accuracy = (accuracy(train_prediction0.eval(), train_1hot_labels[0 * (FLAGS_test_size/10): 1 * (FLAGS_test_size/10)]) + \\\n",
      "                      accuracy(train_prediction1.eval(), train_1hot_labels[1 * (FLAGS_test_size/10): 2 * (FLAGS_test_size/10)]) + \\\n",
      "                      accuracy(train_prediction2.eval(), train_1hot_labels[2 * (FLAGS_test_size/10): 3 * (FLAGS_test_size/10)]) + \\\n",
      "                      accuracy(train_prediction3.eval(), train_1hot_labels[3 * (FLAGS_test_size/10): 4 * (FLAGS_test_size/10)]) + \\\n",
      "                      accuracy(train_prediction4.eval(), train_1hot_labels[4 * (FLAGS_test_size/10): 5 * (FLAGS_test_size/10)]) + \\\n",
      "                      accuracy(train_prediction5.eval(), train_1hot_labels[5 * (FLAGS_test_size/10): 6 * (FLAGS_test_size/10)]) + \\\n",
      "                      accuracy(train_prediction6.eval(), train_1hot_labels[6 * (FLAGS_test_size/10): 7 * (FLAGS_test_size/10)]) + \\\n",
      "                      accuracy(train_prediction7.eval(), train_1hot_labels[7 * (FLAGS_test_size/10): 8 * (FLAGS_test_size/10)]) + \\\n",
      "                      accuracy(train_prediction8.eval(), train_1hot_labels[8 * (FLAGS_test_size/10): 9 * (FLAGS_test_size/10)]) + \\\n",
      "                      accuracy(train_prediction9.eval(), train_1hot_labels[9 * (FLAGS_test_size/10):10 * (FLAGS_test_size/10)])) / 10.0\n",
      "    \n",
      "    print(\"\\nTraining accuracy without the dropout layers: %.1f%%\" % train_accuracy)\n",
      "    \n",
      "    val_accuracy = (accuracy(val_prediction0.eval(), val_1hot_labels[0 * (FLAGS_val_size/10): 1 * (FLAGS_val_size/10)]) + \\\n",
      "                    accuracy(val_prediction1.eval(), val_1hot_labels[1 * (FLAGS_val_size/10): 2 * (FLAGS_val_size/10)]) + \\\n",
      "                    accuracy(val_prediction2.eval(), val_1hot_labels[2 * (FLAGS_val_size/10): 3 * (FLAGS_val_size/10)]) + \\\n",
      "                    accuracy(val_prediction3.eval(), val_1hot_labels[3 * (FLAGS_val_size/10): 4 * (FLAGS_val_size/10)]) + \\\n",
      "                    accuracy(val_prediction4.eval(), val_1hot_labels[4 * (FLAGS_val_size/10): 5 * (FLAGS_val_size/10)]) + \\\n",
      "                    accuracy(val_prediction5.eval(), val_1hot_labels[5 * (FLAGS_val_size/10): 6 * (FLAGS_val_size/10)]) + \\\n",
      "                    accuracy(val_prediction6.eval(), val_1hot_labels[6 * (FLAGS_val_size/10): 7 * (FLAGS_val_size/10)]) + \\\n",
      "                    accuracy(val_prediction7.eval(), val_1hot_labels[7 * (FLAGS_val_size/10): 8 * (FLAGS_val_size/10)]) + \\\n",
      "                    accuracy(val_prediction8.eval(), val_1hot_labels[8 * (FLAGS_val_size/10): 9 * (FLAGS_val_size/10)]) + \\\n",
      "                    accuracy(val_prediction9.eval(), val_1hot_labels[9 * (FLAGS_val_size/10):10 * (FLAGS_val_size/10)])) / 10.0\n",
      "        \n",
      "    print(\"\\nValidation accuracy without the dropout layers: %.1f%%\" % val_accuracy)\n",
      "    \n",
      "    test_accuracy = (accuracy(test_prediction0.eval(), test_1hot_labels[0 * (FLAGS_test_size/10): 1 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction1.eval(), test_1hot_labels[1 * (FLAGS_test_size/10): 2 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction2.eval(), test_1hot_labels[2 * (FLAGS_test_size/10): 3 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction3.eval(), test_1hot_labels[3 * (FLAGS_test_size/10): 4 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction4.eval(), test_1hot_labels[4 * (FLAGS_test_size/10): 5 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction5.eval(), test_1hot_labels[5 * (FLAGS_test_size/10): 6 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction6.eval(), test_1hot_labels[6 * (FLAGS_test_size/10): 7 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction7.eval(), test_1hot_labels[7 * (FLAGS_test_size/10): 8 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction8.eval(), test_1hot_labels[8 * (FLAGS_test_size/10): 9 * (FLAGS_test_size/10)]) + \\\n",
      "                     accuracy(test_prediction9.eval(), test_1hot_labels[9 * (FLAGS_test_size/10):10 * (FLAGS_test_size/10)])) / 10.0\n",
      "    \n",
      "    print(\"\\nTest accuracy without the dropout layers: %.1f%%\" % test_accuracy)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Model restored.\n",
        "\n",
        "Training accuracy without the dropout layers: 87.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Validation accuracy without the dropout layers: 86.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Test accuracy without the dropout layers: 66.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 24
    }
   ],
   "metadata": {}
  }
 ]
}