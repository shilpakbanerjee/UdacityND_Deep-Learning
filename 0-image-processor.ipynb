{
 "metadata": {
  "name": "",
  "signature": "sha256:0582087c560efa97f8c02a58cacf62ff09e0dec38859b47222c27a5abdfafe0a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import math\n",
      "import random\n",
      "import os\n",
      "import tarfile\n",
      "import sys\n",
      "import h5py\n",
      "from six.moves import cPickle as pickle\n",
      "from PIL import Image\n",
      "from scipy import ndimage\n",
      "import tensorflow as tf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(133)\n",
      "\n",
      "def maybe_extract(filename, force=False):\n",
      "  root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
      "  if os.path.isdir(root) and not force:\n",
      "    # You may override by setting force=True.\n",
      "    print('%s folder already present - Skipping extraction of %s.' % (root, filename))\n",
      "  else:\n",
      "    print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
      "    tar = tarfile.open(filename)\n",
      "    sys.stdout.flush()\n",
      "    tar.extractall()\n",
      "    tar.close()\n",
      "    print('Created!')\n",
      "  return \n",
      "  \n",
      "maybe_extract('train.tar.gz')\n",
      "maybe_extract('test.tar.gz')\n",
      "maybe_extract('extra.tar.gz')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train folder already present - Skipping extraction of train.tar.gz.\n",
        "test folder already present - Skipping extraction of test.tar.gz.\n",
        "extra folder already present - Skipping extraction of extra.tar.gz.\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_train = 2\n",
      "n_test = 2\n",
      "n_extra = 2\n",
      "\n",
      "print('Displaying', n_train, 'random pictures from the training set')\n",
      "for i in range(n_train):\n",
      "    img = Image.open('train'+'/'+os.listdir('train')[random.randrange(len(os.listdir('train')))])\n",
      "    img.show()\n",
      "    img_resized = img.resize((32,32))\n",
      "    img_resized.show()\n",
      "                            \n",
      "    \n",
      "print('Displaying', n_test, 'random pictures from the test set')\n",
      "for i in range(n_test):\n",
      "    img = Image.open('test'+'/'+os.listdir('test')[random.randrange(len(os.listdir('test')))])\n",
      "    img.show()\n",
      "    img_resized = img.resize((32,32))\n",
      "    img_resized.show()\n",
      "    \n",
      "print('Displaying', n_test, 'random pictures from the extra set')\n",
      "for i in range(n_test):\n",
      "    img = Image.open('extra'+'/'+os.listdir('extra')[random.randrange(len(os.listdir('extra')))])\n",
      "    img.show()\n",
      "    img_resized = img.resize((32,32))\n",
      "    img_resized.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('Displaying', 2, 'random pictures from the training set')\n",
        "('Displaying', 2, 'random pictures from the test set')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Displaying', 2, 'random pictures from the extra set')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Following portion of the code is due to user *Hang_Yao* from the Udacity forum. \n",
      "url: https://discussions.udacity.com/t/how-to-deal-with-mat-files/160657/5?u=shilpak_189372484889"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class DigitStructFile:\n",
      "    def __init__(self, inf):\n",
      "        self.inf = h5py.File(inf, 'r')\n",
      "        self.digitStructName = self.inf['digitStruct']['name']\n",
      "        self.digitStructBbox = self.inf['digitStruct']['bbox']\n",
      "\n",
      "\n",
      "    def getName(self,n):\n",
      "        return ''.join([chr(c[0]) for c in self.inf[self.digitStructName[n][0]].value])\n",
      "\n",
      "\n",
      "    def bboxHelper(self,attr):\n",
      "        if (len(attr) > 1):\n",
      "            attr = [self.inf[attr.value[j].item()].value[0][0] for j in range(len(attr))]\n",
      "        else:\n",
      "            attr = [attr.value[0][0]]\n",
      "        return attr\n",
      "\n",
      "\n",
      "    def getBbox(self,n):\n",
      "        bbox = {}\n",
      "        bb = self.digitStructBbox[n].item()\n",
      "        bbox['height'] = self.bboxHelper(self.inf[bb][\"height\"])\n",
      "        bbox['label'] = self.bboxHelper(self.inf[bb][\"label\"])\n",
      "        bbox['left'] = self.bboxHelper(self.inf[bb][\"left\"])\n",
      "        bbox['top'] = self.bboxHelper(self.inf[bb][\"top\"])\n",
      "        bbox['width'] = self.bboxHelper(self.inf[bb][\"width\"])\n",
      "        return bbox\n",
      "\n",
      "    def getDigitStructure(self,n):\n",
      "        s = self.getBbox(n)\n",
      "        s['name']=self.getName(n)\n",
      "        return s\n",
      "     \n",
      "    def getAllDigitStructure(self):\n",
      "        return [self.getDigitStructure(i) for i in range(len(self.digitStructName))]\n",
      "\n",
      "\n",
      "    def getAllDigitStructure_ByDigit(self):\n",
      "        pictDat = self.getAllDigitStructure()\n",
      "        result = []\n",
      "        structCnt = 1\n",
      "        for i in range(len(pictDat)):\n",
      "            item = { 'filename' : pictDat[i][\"name\"] }\n",
      "            figures = []\n",
      "            for j in range(len(pictDat[i]['height'])):\n",
      "               figure = {}\n",
      "               figure['height'] = pictDat[i]['height'][j]\n",
      "               figure['label']  = pictDat[i]['label'][j]\n",
      "               figure['left']   = pictDat[i]['left'][j]\n",
      "               figure['top']    = pictDat[i]['top'][j]\n",
      "               figure['width']  = pictDat[i]['width'][j]\n",
      "               figures.append(figure)\n",
      "            structCnt = structCnt + 1\n",
      "            item['boxes'] = figures\n",
      "            result.append(item)\n",
      "        return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fin = 'test/digitStruct.mat'\n",
      "dsf = DigitStructFile(fin)\n",
      "test_data = dsf.getAllDigitStructure_ByDigit()\n",
      "\n",
      "print('Got test data')\n",
      "\n",
      "fin = 'train/digitStruct.mat'\n",
      "dsf = DigitStructFile(fin)\n",
      "train_data = dsf.getAllDigitStructure_ByDigit()\n",
      "\n",
      "print('Got train data')\n",
      "\n",
      "fin = 'extra/digitStruct.mat'\n",
      "dsf = DigitStructFile(fin)\n",
      "extra_data = dsf.getAllDigitStructure_ByDigit()\n",
      "\n",
      "print('Got extra data')\n",
      "\n",
      "del fin"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got test data\n",
        "Got train data"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Got extra data"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def labels_dict(data_set):\n",
      "    l_dict = {}\n",
      "    for item in data_set:\n",
      "        l_dict[item['filename']] = item['boxes']        \n",
      "    return l_dict\n",
      "\n",
      "test_labels_dict = labels_dict(test_data)\n",
      "train_labels_dict = labels_dict(train_data)\n",
      "extra_labels_dict = labels_dict(extra_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# IGNORE BOX\n",
      " \n",
      "print(test_data[19])\n",
      "print(test_labels_dict['20.png'])\n",
      "print(test_data[19]['boxes'][0]['left'])\n",
      "#img = Image.open('test/20.png')\n",
      "#img.show()   \n",
      "#print(img.size)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'boxes': [{'width': 14.0, 'top': 17.0, 'label': 1.0, 'left': 143.0, 'height': 24.0}, {'width': 14.0, 'top': 17.0, 'label': 5.0, 'left': 156.0, 'height': 24.0}, {'width': 13.0, 'top': 20.0, 'label': 1.0, 'left': 167.0, 'height': 24.0}], 'filename': '20.png'}\n",
        "[{'width': 14.0, 'top': 17.0, 'label': 1.0, 'left': 143.0, 'height': 24.0}, {'width': 14.0, 'top': 17.0, 'label': 5.0, 'left': 156.0, 'height': 24.0}, {'width': 13.0, 'top': 20.0, 'label': 1.0, 'left': 167.0, 'height': 24.0}]\n",
        "143.0\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l_list=[]\n",
      "\n",
      "for item in test_data:\n",
      "    l_list.append(len(item['boxes']))\n",
      "\n",
      "print('Stats for test data:')\n",
      "print(len(l_list))\n",
      "print(l_list.count(0),l_list.count(1),l_list.count(2),l_list.count(3),l_list.count(4),l_list.count(5),l_list.count(6))\n",
      "\n",
      "for item in train_data:\n",
      "    l_list.append(len(item['boxes']))\n",
      "\n",
      "print('\\nStats for test data:')\n",
      "print(len(l_list))\n",
      "print(l_list.count(0),l_list.count(1),l_list.count(2),l_list.count(3),l_list.count(4),l_list.count(5),l_list.count(6))\n",
      "\n",
      "for item in extra_data:\n",
      "    l_list.append(len(item['boxes']))\n",
      "\n",
      "print('\\nStats for extra data:')\n",
      "print(len(l_list))\n",
      "print(l_list.count(0),l_list.count(1),l_list.count(2),l_list.count(3),l_list.count(4),l_list.count(5),l_list.count(6))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Stats for test data:\n",
        "13068\n",
        "(0, 2483, 8356, 2081, 146, 2, 0)\n",
        "\n",
        "Stats for test data:\n",
        "46470\n",
        "(0, 7620, 26486, 10772, 1580, 11, 1)\n",
        "\n",
        "Stats for extra data:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "248823\n",
        "(0, 17005, 98212, 117561, 15918, 126, 1)\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FLAGS_image_size = 32\n",
      "\n",
      "def process_images(folder, data_dict):\n",
      "    \n",
      "    process_folder = folder + '_processed'\n",
      "    \n",
      "    if os.path.exists(process_folder):\n",
      "        print('%s folder already present - Skipping processingg images in %s folder.' % (process_folder, folder))\n",
      "    else:\n",
      "        os.makedirs(process_folder)\n",
      "        image_files = os.listdir(folder)\n",
      "        for image in image_files:\n",
      "            image_file = os.path.join(folder, image)\n",
      "            try:\n",
      "                img = Image.open(image_file)\n",
      "                image_length, image_height = img.size\n",
      "                length = len(data_dict[image])\n",
      "                left, right, top, bottom = [], [], [], []\n",
      "                for i in range(length):\n",
      "                    left.append(data_dict[image][i]['left'])\n",
      "                    right.append(data_dict[image][i]['left'] + data_dict[image][i]['width'])\n",
      "                    top.append(data_dict[image][i]['top'])\n",
      "                    bottom.append(data_dict[image][i]['top'] + data_dict[image][i]['height'])\n",
      "                number_length = max(right)-min(left)\n",
      "                number_height = min(top)-max(bottom)\n",
      "                l_crop = np.int32(max([min(left) - .3 * number_length, 0]))\n",
      "                r_crop = np.int32(min([max(right) + .3 * number_length, image_length]))\n",
      "                t_crop = np.int32(max([min(top) - .3 * image_height, 0]))\n",
      "                b_crop = np.int32(min([max(bottom) + .3 * image_height, image_height]))\n",
      "                img = img.crop([l_crop,t_crop,r_crop,b_crop])\n",
      "                img = img.resize((FLAGS_image_size, FLAGS_image_size))\n",
      "                img.save(process_folder+'/'+image, 'PNG') \n",
      "            except IOError as e:\n",
      "                print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
      "        print('%s folder created.' % process_folder)    \n",
      "    return"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "process_images('test', test_labels_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('Could not read:', 'test/digitStruct.mat', ':', IOError(\"cannot identify image file 'test/digitStruct.mat'\",), \"- it's ok, skipping.\")\n",
        "('Could not read:', 'test/see_bboxes.m', ':', IOError(\"cannot identify image file 'test/see_bboxes.m'\",), \"- it's ok, skipping.\")"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "test_processed folder created."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "process_images('train', train_labels_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('Could not read:', 'train/digitStruct.mat', ':', IOError(\"cannot identify image file 'train/digitStruct.mat'\",), \"- it's ok, skipping.\")\n",
        "('Could not read:', 'train/see_bboxes.m', ':', IOError(\"cannot identify image file 'train/see_bboxes.m'\",), \"- it's ok, skipping.\")"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train_processed folder created."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "process_images('extra', extra_labels_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('Could not read:', 'extra/digitStruct.mat', ':', IOError(\"cannot identify image file 'extra/digitStruct.mat'\",), \"- it's ok, skipping.\")\n",
        "('Could not read:', 'extra/see_bboxes.m', ':', IOError(\"cannot identify image file 'extra/see_bboxes.m'\",), \"- it's ok, skipping.\")"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "extra_processed folder created."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FLAGS_pixel_depth = 255.0  # Number of levels per pixel.\n",
      "FLAGS_num_labels = 10\n",
      "\n",
      "\n",
      "def load_data(folder, data_dict, min_num_images):\n",
      "  \n",
      "    image_files = os.listdir(folder)\n",
      "    dataset = np.ndarray(shape=(len(image_files), FLAGS_image_size, FLAGS_image_size, 1),\n",
      "                         dtype=np.float32)\n",
      "    labelset = np.ndarray(shape=(len(image_files), 7))\n",
      "    \n",
      "    num_images = 0\n",
      "    for image in image_files:\n",
      "        \n",
      "        image_file = os.path.join(folder, image)\n",
      "        try:\n",
      "            image_data = ndimage.imread(image_file).astype(float)   \n",
      "            image_data = np.dot(image_data[...,:3], [0.299, 0.587, 0.114]).reshape(FLAGS_image_size,FLAGS_image_size,1)\n",
      "            image_data = (image_data - FLAGS_pixel_depth / 2.0) / FLAGS_pixel_depth\n",
      "            dataset[num_images, :, :, :] = image_data \n",
      "            temp_labels = []\n",
      "            for i in range(len(data_dict[image])):\n",
      "                temp_labels.append(data_dict[image][i]['label'])\n",
      "            labelset[num_images, :] = temp_labels + [-1] * (6-len(data_dict[image])) + [len(data_dict[image])]\n",
      "            num_images = num_images + 1\n",
      "        except IOError as e:\n",
      "            print('Could not process:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
      "    \n",
      "    dataset = dataset[0:min_num_images, :, :, :]\n",
      "    labelset = labelset[0:min_num_images, :]\n",
      "    \n",
      "    if min_num_images > -1 and num_images < min_num_images:\n",
      "        raise Exception('Many fewer images than expected: %d < %d' % (num_images, min_num_images))\n",
      "    \n",
      "    print('Full dataset tensor:', dataset.shape)\n",
      "    print('Mean:', np.mean(dataset))\n",
      "    print('Standard deviation:', np.std(dataset))\n",
      "    return dataset, labelset\n",
      "        \n",
      "\n",
      "def maybe_pickle(data_folder, label_dict, min_num_images, force=False):\n",
      "  \n",
      "    set_image_filename = data_folder + '.pickle'\n",
      "    set_label_filename = data_folder + '_labels.pickle'\n",
      "    T = os.path.exists(set_image_filename) and os.path.exists(set_label_filename)\n",
      "    \n",
      "    if T and not force:\n",
      "        print('%s and %s already present - Skipping pickling.' % (set_image_filename, set_label_filename))\n",
      "    else:\n",
      "        print('Pickling %s.' % set_image_filename)        \n",
      "        dataset, labelset = load_data(data_folder, label_dict, min_num_images)\n",
      "        try:\n",
      "            with open(set_image_filename, 'wb') as f:\n",
      "                pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
      "        except Exception as e:\n",
      "            print('Unable to save data to', set_image_filename, ':', e)  \n",
      "        try:\n",
      "            with open(set_label_filename, 'wb') as g:\n",
      "                pickle.dump(labelset, g, pickle.HIGHEST_PROTOCOL)\n",
      "        except Exception as e:\n",
      "            print('Unable to save data to', set_label_filename, ':', e)\n",
      "  \n",
      "    return set_image_filename, set_label_filename"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_datasets, test_labelset = maybe_pickle('test_processed', test_labels_dict, -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Pickling test_processed.pickle.\n",
        "('Full dataset tensor:', (13067, 32, 32, 1))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Mean:', -0.058037952)\n",
        "('Standard deviation:', 0.22898267)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_datasets, train_labelset = maybe_pickle('train_processed', train_labels_dict, -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Pickling train_processed.pickle.\n",
        "('Full dataset tensor:', (33401, 32, 32, 1))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Mean:', -0.054143108)\n",
        "('Standard deviation:', 0.2006288)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extra_datasets, extra_labelset = maybe_pickle('extra_processed', extra_labels_dict, -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Pickling extra_processed.pickle.\n",
        "('Full dataset tensor:', (202352, 32, 32, 1))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Mean:', -0.058883846)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Standard deviation:', 0.20043345)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_test = 1\n",
      "n_train = 2\n",
      "n_extra = 1\n",
      "\n",
      "buf = pickle.load(file(test_datasets))\n",
      "label_buf = pickle.load(file(test_labelset))\n",
      "for i in range(n_test):\n",
      "    j = random.randrange(np.shape(buf)[0])\n",
      "    plt.imshow(buf[j], cmap = 'Greys_r')\n",
      "    plt.title(label_buf[j])\n",
      "    plt.show()\n",
      "    \n",
      "buf = pickle.load(file(train_datasets))\n",
      "label_buf = pickle.load(file(train_labelset))\n",
      "for i in range(n_train):\n",
      "    j = random.randrange(np.shape(buf)[0])\n",
      "    plt.imshow(buf[j], cmap = 'Greys_r')\n",
      "    plt.title(label_buf[j])\n",
      "    plt.show()\n",
      "    \n",
      "buf = pickle.load(file(extra_datasets))\n",
      "label_buf = pickle.load(file(extra_labelset))\n",
      "for i in range(n_extra):\n",
      "    j = random.randrange(np.shape(buf)[0])\n",
      "    plt.imshow(buf[j], cmap = 'Greys_r')\n",
      "    plt.title(label_buf[j])\n",
      "    plt.show()\n",
      "\n",
      "del buf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}